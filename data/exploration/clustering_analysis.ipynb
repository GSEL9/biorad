{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Analysis\n",
    "\n",
    "## DGUFS\n",
    "\n",
    "**To Do**\n",
    "* Compare detected clusters to non-redundant/redundant feature sets derived from model comparison experiments.\n",
    "* Apply group LASSO to clusters from DGUFS. DGUFS performs siml. clustering and feature selection. Optimize DGUFS cluster quality according to metric from paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "import concensus_clustering\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from sklearn.cluster.bicluster import SpectralCoclustering\n",
    "from sklearn.cluster.bicluster import SpectralBiclustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_categories = [\n",
    "    'shape',\n",
    "    'firstorder',\n",
    "    'glcm',\n",
    "    'glrlm',\n",
    "    'glszm',\n",
    "    'gldm',\n",
    "    'ngtdm',\n",
    "    'PETparam', \n",
    "    'clinical'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_counts(_):\n",
    "    \n",
    "    return {\n",
    "        'shape': 0,\n",
    "        'firstorder': 0,\n",
    "        'glcm': 0,\n",
    "        'glrlm': 0,\n",
    "        'glszm': 0,\n",
    "        'gldm': 0,\n",
    "        'ngtdm': 0,\n",
    "        'PETparam': 0,\n",
    "        'clinical': 0,\n",
    "    }\n",
    "\n",
    "\n",
    "def _update_count(pet_output, ct_output, key):\n",
    "\n",
    "    if 'PET' in key:\n",
    "        pet_output[key]['PET'] += 1\n",
    "    else:\n",
    "        results[key]['CT'] += 1\n",
    "            \n",
    "    return pet_output, ct_output\n",
    "\n",
    "\n",
    "def _norm_count(results, key, tot_counts):\n",
    "    \n",
    "    if 'PET' in key:\n",
    "        results[key]['PET'] /= tot_counts[key]\n",
    "    else:\n",
    "        results[key]['CT'] /= tot_counts[key]\n",
    "            \n",
    "    return results\n",
    "\n",
    "\n",
    "def to_feature_categories(cluster_indices):\n",
    "    \n",
    "    pet_output = category_counts(None)\n",
    "    ct_output = category_counts(None)\n",
    "    for label in X.columns[cluster_indices]:\n",
    "        if 'shape' in label:\n",
    "            pet_output, ct_output = _update_count(pet_output, ct_output, 'shape')\n",
    "        elif 'firstorder' in label:\n",
    "            output = _update_count(output, 'firstorder')\n",
    "        elif 'glcm' in label:\n",
    "            output = _update_count(output, 'glcm')\n",
    "        elif 'glrlm' in label:\n",
    "            output = _update_count(output, 'glrlm')\n",
    "        elif 'glszm' in label:\n",
    "            output = _update_count(output, 'glszm')\n",
    "        elif 'gldm' in label:\n",
    "            output = _update_count(output, 'gldm')\n",
    "        elif 'ngtdm' in label:\n",
    "            output = _update_count(output, 'ngtdm')\n",
    "        elif 'PETparam' in label:\n",
    "            output = _update_count(output, 'PETparam')\n",
    "        else:\n",
    "            output = _update_count(output, 'clinical')\n",
    "        \n",
    "    feature_counts = {\n",
    "        'shape': 13,\n",
    "        'firstorder': 54,\n",
    "        'glcm': 69,\n",
    "        'glrlm': 48,\n",
    "        'glszm': 48,\n",
    "        'gldm': 42,\n",
    "        'ngtdm': 15,\n",
    "        'PETparam': 3, \n",
    "        'clinical': 42\n",
    "    }\n",
    "    for label in output.keys():\n",
    "        output = _norm_count(output, label, feature_counts)\n",
    "        \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: For average Pearson use -1.0 * abs(rho). As rho improves \n",
    "# (indicating better results) a larger amount is subtracted to the \n",
    "# output indicating better overall biclusters.\n",
    "def meta_score(scores, weights=None):\n",
    "    \"\"\"The weighted arithmetic mean of multiple scores.\"\"\" \n",
    "    \n",
    "    if weights is None:\n",
    "        weights = [0.5] * len(scores)\n",
    "    \n",
    "    outcome = 0\n",
    "    for score, weight in zip(scores, weights):\n",
    "        outcome = outcome + weight * -1.0 * abs(score)\n",
    "        \n",
    "    return outcome / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biclusters(model, X, param_config):\n",
    "    # Create Bicluster instances tracking detected clusters.\n",
    "    \n",
    "    # Start fresh with each clustering.\n",
    "    _model = deepcopy(model)\n",
    "    \n",
    "    # Set number of clusters to detect and fit model to data.\n",
    "    _model.set_params(**param_config)\n",
    "    _model.fit(X)\n",
    "\n",
    "    rows, cols = _model.rows_, _model.columns_\n",
    "    # Sanity check.\n",
    "    assert np.shape(rows)[0] == np.shape(cols)[0]\n",
    "    \n",
    "    biclusters = concensus_clustering.Biclusters(\n",
    "        rows=rows, cols=cols, data=X\n",
    "    )\n",
    "    return biclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker_coords(model, num_clusters):\n",
    "    # Collect coordinates for biclusters with a checkerborad structure.\n",
    "    \n",
    "    tot_num_clusters = num_clusters[0] * num_clusters[1]\n",
    "    coords = pd.DataFrame(\n",
    "        np.zeros((tot_num_clusters, 4)),\n",
    "        columns=('y1', 'y2', 'x1', 'x2')\n",
    "    )\n",
    "    \n",
    "    num, prev_rows = 0, 0\n",
    "    for row_num in range(num_clusters[0]):\n",
    "        nrows = np.sum(model.rows_[row_num])\n",
    "\n",
    "        prev_cols = 0\n",
    "        for col_num in range(num_clusters[1]):\n",
    "            ncols = np.sum(model.columns_[col_num])\n",
    "\n",
    "            coords.iloc[num, 0] = prev_rows + 1\n",
    "            coords.iloc[num, 1] = prev_rows + nrows\n",
    "            coords.iloc[num, 2] = prev_cols\n",
    "            coords.iloc[num, 3] = prev_cols + ncols\n",
    "\n",
    "            num += 1\n",
    "\n",
    "            prev_cols += ncols\n",
    "        prev_rows += nrows - 1\n",
    "\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic_coords(model, num_clusters):\n",
    "    # Collect coordinates for block diagonal biclusters.\n",
    "\n",
    "    coords = pd.DataFrame(\n",
    "        np.zeros((num_clusters, 4)),\n",
    "        columns=('y1', 'y2', 'x1', 'x2')\n",
    "    )\n",
    "    prev_rows, prev_cols = 0, 0\n",
    "    for num, row_bic in enumerate(model.rows_):\n",
    "        num_rows = np.sum(row_bic)\n",
    "        num_cols = np.sum(model.columns_[num])\n",
    "\n",
    "        coords.iloc[num, 0] = prev_rows\n",
    "        coords.iloc[num, 1] = prev_rows + num_rows\n",
    "        coords.iloc[num, 2] = prev_cols\n",
    "        coords.iloc[num, 3] = prev_cols + num_cols\n",
    "\n",
    "        prev_rows += num_rows\n",
    "        prev_cols += num_cols\n",
    "\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('./../../../data_source/to_analysis/target_dfs.csv', index_col=0)\n",
    "y = np.squeeze(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_shape_Elongation</th>\n",
       "      <th>original_shape_Flatness</th>\n",
       "      <th>original_shape_LeastAxis</th>\n",
       "      <th>original_shape_MajorAxis</th>\n",
       "      <th>original_shape_Maximum2DDiameterColumn</th>\n",
       "      <th>original_shape_Maximum2DDiameterRow</th>\n",
       "      <th>original_shape_Maximum2DDiameterSlice</th>\n",
       "      <th>original_shape_Maximum3DDiameter</th>\n",
       "      <th>original_shape_MinorAxis</th>\n",
       "      <th>original_shape_Sphericity</th>\n",
       "      <th>...</th>\n",
       "      <th>PET_original_gldm_SmallDependenceHighGrayLevelEmphasis.2</th>\n",
       "      <th>PET_original_gldm_SmallDependenceLowGrayLevelEmphasis.2</th>\n",
       "      <th>PET_original_ngtdm_Busyness.2</th>\n",
       "      <th>PET_original_ngtdm_Coarseness.2</th>\n",
       "      <th>PET_original_ngtdm_Complexity.2</th>\n",
       "      <th>PET_original_ngtdm_Contrast.2</th>\n",
       "      <th>PET_original_ngtdm_Strength.2</th>\n",
       "      <th>PETparam_SUVpeak</th>\n",
       "      <th>PETparam_MTV</th>\n",
       "      <th>PETparam_TLG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.738882</td>\n",
       "      <td>0.723925</td>\n",
       "      <td>27.060529</td>\n",
       "      <td>37.380273</td>\n",
       "      <td>41.976184</td>\n",
       "      <td>44.598206</td>\n",
       "      <td>42.720019</td>\n",
       "      <td>45.617979</td>\n",
       "      <td>27.619612</td>\n",
       "      <td>0.661532</td>\n",
       "      <td>...</td>\n",
       "      <td>4430.229066</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>27568.285932</td>\n",
       "      <td>0.296325</td>\n",
       "      <td>70.049351</td>\n",
       "      <td>21.616549</td>\n",
       "      <td>7.384</td>\n",
       "      <td>124.870726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.796900</td>\n",
       "      <td>0.629917</td>\n",
       "      <td>19.845151</td>\n",
       "      <td>31.504408</td>\n",
       "      <td>38.587563</td>\n",
       "      <td>35.468296</td>\n",
       "      <td>29.410882</td>\n",
       "      <td>38.704005</td>\n",
       "      <td>25.105855</td>\n",
       "      <td>0.701721</td>\n",
       "      <td>...</td>\n",
       "      <td>4270.509796</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.027591</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>31578.673152</td>\n",
       "      <td>0.271854</td>\n",
       "      <td>156.965282</td>\n",
       "      <td>15.296275</td>\n",
       "      <td>3.406</td>\n",
       "      <td>41.554406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600926</td>\n",
       "      <td>0.535140</td>\n",
       "      <td>22.515072</td>\n",
       "      <td>42.073251</td>\n",
       "      <td>46.065171</td>\n",
       "      <td>43.011626</td>\n",
       "      <td>32.015621</td>\n",
       "      <td>46.454279</td>\n",
       "      <td>25.282894</td>\n",
       "      <td>0.762365</td>\n",
       "      <td>...</td>\n",
       "      <td>4096.292481</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>24870.405544</td>\n",
       "      <td>0.230801</td>\n",
       "      <td>64.918103</td>\n",
       "      <td>14.473272</td>\n",
       "      <td>7.934</td>\n",
       "      <td>86.228420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.784571</td>\n",
       "      <td>0.414247</td>\n",
       "      <td>30.263897</td>\n",
       "      <td>73.057649</td>\n",
       "      <td>74.148500</td>\n",
       "      <td>80.956779</td>\n",
       "      <td>65.764732</td>\n",
       "      <td>83.438600</td>\n",
       "      <td>57.318945</td>\n",
       "      <td>0.520001</td>\n",
       "      <td>...</td>\n",
       "      <td>1198.601513</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.139365</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>11651.530760</td>\n",
       "      <td>0.081103</td>\n",
       "      <td>15.731158</td>\n",
       "      <td>10.510859</td>\n",
       "      <td>26.926</td>\n",
       "      <td>205.413389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.690320</td>\n",
       "      <td>0.539743</td>\n",
       "      <td>19.449801</td>\n",
       "      <td>36.035312</td>\n",
       "      <td>33.286634</td>\n",
       "      <td>38.013156</td>\n",
       "      <td>33.015148</td>\n",
       "      <td>43.150898</td>\n",
       "      <td>24.875896</td>\n",
       "      <td>0.643822</td>\n",
       "      <td>...</td>\n",
       "      <td>1122.798029</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.048381</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>7160.791790</td>\n",
       "      <td>0.118371</td>\n",
       "      <td>29.024761</td>\n",
       "      <td>7.213190</td>\n",
       "      <td>6.041</td>\n",
       "      <td>32.103770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         original_shape_Elongation  original_shape_Flatness  \\\n",
       "patient                                                       \n",
       "2                         0.738882                 0.723925   \n",
       "4                         0.796900                 0.629917   \n",
       "5                         0.600926                 0.535140   \n",
       "8                         0.784571                 0.414247   \n",
       "10                        0.690320                 0.539743   \n",
       "\n",
       "         original_shape_LeastAxis  original_shape_MajorAxis  \\\n",
       "patient                                                       \n",
       "2                       27.060529                 37.380273   \n",
       "4                       19.845151                 31.504408   \n",
       "5                       22.515072                 42.073251   \n",
       "8                       30.263897                 73.057649   \n",
       "10                      19.449801                 36.035312   \n",
       "\n",
       "         original_shape_Maximum2DDiameterColumn  \\\n",
       "patient                                           \n",
       "2                                     41.976184   \n",
       "4                                     38.587563   \n",
       "5                                     46.065171   \n",
       "8                                     74.148500   \n",
       "10                                    33.286634   \n",
       "\n",
       "         original_shape_Maximum2DDiameterRow  \\\n",
       "patient                                        \n",
       "2                                  44.598206   \n",
       "4                                  35.468296   \n",
       "5                                  43.011626   \n",
       "8                                  80.956779   \n",
       "10                                 38.013156   \n",
       "\n",
       "         original_shape_Maximum2DDiameterSlice  \\\n",
       "patient                                          \n",
       "2                                    42.720019   \n",
       "4                                    29.410882   \n",
       "5                                    32.015621   \n",
       "8                                    65.764732   \n",
       "10                                   33.015148   \n",
       "\n",
       "         original_shape_Maximum3DDiameter  original_shape_MinorAxis  \\\n",
       "patient                                                               \n",
       "2                               45.617979                 27.619612   \n",
       "4                               38.704005                 25.105855   \n",
       "5                               46.454279                 25.282894   \n",
       "8                               83.438600                 57.318945   \n",
       "10                              43.150898                 24.875896   \n",
       "\n",
       "         original_shape_Sphericity      ...       \\\n",
       "patient                                 ...        \n",
       "2                         0.661532      ...        \n",
       "4                         0.701721      ...        \n",
       "5                         0.762365      ...        \n",
       "8                         0.520001      ...        \n",
       "10                        0.643822      ...        \n",
       "\n",
       "         PET_original_gldm_SmallDependenceHighGrayLevelEmphasis.2  \\\n",
       "patient                                                             \n",
       "2                                              4430.229066          \n",
       "4                                              4270.509796          \n",
       "5                                              4096.292481          \n",
       "8                                              1198.601513          \n",
       "10                                             1122.798029          \n",
       "\n",
       "         PET_original_gldm_SmallDependenceLowGrayLevelEmphasis.2  \\\n",
       "patient                                                            \n",
       "2                                                 0.000370         \n",
       "4                                                 0.000527         \n",
       "5                                                 0.000460         \n",
       "8                                                 0.000319         \n",
       "10                                                0.000459         \n",
       "\n",
       "         PET_original_ngtdm_Busyness.2  PET_original_ngtdm_Coarseness.2  \\\n",
       "patient                                                                   \n",
       "2                             0.025559                         0.004672   \n",
       "4                             0.027591                         0.007443   \n",
       "5                             0.022439                         0.005178   \n",
       "8                             0.139365                         0.001371   \n",
       "10                            0.048381                         0.005789   \n",
       "\n",
       "         PET_original_ngtdm_Complexity.2  PET_original_ngtdm_Contrast.2  \\\n",
       "patient                                                                   \n",
       "2                           27568.285932                       0.296325   \n",
       "4                           31578.673152                       0.271854   \n",
       "5                           24870.405544                       0.230801   \n",
       "8                           11651.530760                       0.081103   \n",
       "10                           7160.791790                       0.118371   \n",
       "\n",
       "         PET_original_ngtdm_Strength.2  PETparam_SUVpeak  PETparam_MTV  \\\n",
       "patient                                                                  \n",
       "2                            70.049351         21.616549         7.384   \n",
       "4                           156.965282         15.296275         3.406   \n",
       "5                            64.918103         14.473272         7.934   \n",
       "8                            15.731158         10.510859        26.926   \n",
       "10                           29.024761          7.213190         6.041   \n",
       "\n",
       "         PETparam_TLG  \n",
       "patient                \n",
       "2          124.870726  \n",
       "4           41.554406  \n",
       "5           86.228420  \n",
       "8          205.413389  \n",
       "10          32.103770  \n",
       "\n",
       "[5 rows x 610 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('./../../../data_source/to_analysis/no_filter_concat.csv', index_col=0)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 610)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = StandardScaler().fit_transform(X.values)\n",
    "X_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Biclustering\n",
    "\n",
    "Ref: Kluger, Yuval, et. al., 2003. Spectral biclustering of microarray data: coclustering genes and conditions.\n",
    "* [blog](http://www.kemaleren.com/post/spectral-biclustering-part-1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:50: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  smsr_values = msr_values / (avg_rows ** 2 * avg_cols ** 2)\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:50: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  smsr_values = msr_values / (avg_rows ** 2 * avg_cols ** 2)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:50: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  smsr_values = msr_values / (avg_rows ** 2 * avg_cols ** 2)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:50: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  smsr_values = msr_values / (avg_rows ** 2 * avg_cols ** 2)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:50: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  smsr_values = msr_values / (avg_rows ** 2 * avg_cols ** 2)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:50: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  smsr_values = msr_values / (avg_rows ** 2 * avg_cols ** 2)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:50: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  smsr_values = msr_values / (avg_rows ** 2 * avg_cols ** 2)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/Desktop/ms/biorad/data/exploration/concensus_clustering.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_cols_std = (avg_cols - np.mean(avg_cols)) / np.std(avg_cols)\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n",
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  n_local_trials = 2 + int(np.log(n_clusters))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "bic_grid = ParameterGrid(\n",
    "    {\n",
    "        'n_clusters': [\n",
    "            np.random.choice(np.arange(30), size=2) for _ in range(25)\n",
    "        ],\n",
    "        'n_components': [6, 9, 10],\n",
    "        'n_best': [1, 3, 6],\n",
    "        \n",
    "    }\n",
    ")\n",
    "# Id config with best score results and plot with grid.\n",
    "bic_scores = {}\n",
    "for num, bic_param_config in enumerate(bic_grid):\n",
    "    try:\n",
    "        bic_model = SpectralBiclustering(\n",
    "            random_state=SEED, method='log', svd_method='arpack'\n",
    "        )\n",
    "        bic_clusters = biclusters(\n",
    "            bic_model, X_std, bic_param_config\n",
    "        )\n",
    "        bic_scores[num] = bic_clusters.external_metrics\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_components': 6, 'n_clusters': array([21, 18]), 'n_best': 3},\n",
       " 0.6052992748819872)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine best biclustering config.\n",
    "avg_bic_scores = []\n",
    "for scores in bic_scores.values():\n",
    "    _, non_inf_idx = np.where(scores.values != float('inf'))\n",
    "    score = sum(scores.values.ravel()[non_inf_idx]) / len(non_inf_idx)\n",
    "    avg_bic_scores.append(score)\n",
    "    \n",
    "best_config = bic_grid[np.argmin(avg_bic_scores)]\n",
    "best_config, min(avg_bic_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_model = SpectralBiclustering(\n",
    "    random_state=SEED, method='log', svd_method='arpack'\n",
    ")\n",
    "bic_model.set_params(**best_config)\n",
    "bic_model.fit(X_std)\n",
    "row_sorted = X_std[np.argsort(bic_model.row_labels_), :]\n",
    "fit_data = row_sorted[:, np.argsort(bic_model.column_labels_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6767676767676767, 0.32323232323232315, 21)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The proportion of patient outcomes per row bicluster.\n",
    "\n",
    "bic_row_ids = []\n",
    "bic_pfs_outcome, bic_not_pfs_outcome = [], []\n",
    "\n",
    "for bic_row_idx in np.unique(bic_model.row_labels_):\n",
    "    # Store cluster index.\n",
    "    bic_row_ids.append(bic_row_idx)\n",
    "    \n",
    "    # ID samples belonging to current cluster.\n",
    "    row_cluster_samples = np.where(bic_model.row_labels_ == bic_row_idx)\n",
    "    \n",
    "    # Store fractions of each outcome for current cluster.\n",
    "    bic_pfs_outcome.append(sum(y[row_cluster_samples] == 0) / np.size(y))\n",
    "    bic_not_pfs_outcome.append(sum(y[row_cluster_samples] == 1) / np.size(y))\n",
    "    \n",
    "sum(bic_pfs_outcome), sum(bic_not_pfs_outcome), len(bic_row_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of features from each feature category per column bicluster.\n",
    "\n",
    "pet_category_stats = {}\n",
    "ct_category_stats = {}\n",
    "\n",
    "for bic_col_idx in np.unique(bic_model.column_labels_):    \n",
    "    # ID samples belonging to current cluster.\n",
    "    col_cluster_samples = np.squeeze(np.where(bic_model.column_labels_ == bic_col_idx))\n",
    "    # Store fractions of present feature categories per modality.\n",
    "    pet_output, ct_output = to_feature_categories(col_cluster_samples)\n",
    "    pet_category_stats[bic_col_idx] = pet_output\n",
    "    ct_category_stats[bic_col_idx] = ct_output\n",
    "    \n",
    "pet_df = pd.DataFrame(pet_category_stats)\n",
    "ct_df = pd.DataFrame(ct_category_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PETparam</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinical</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firstorder</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glcm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gldm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glrlm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glszm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ngtdm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shape</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1         2         3    4    5    6    7    8    9    10  \\\n",
       "PETparam    0.0  0.0  0.333333  0.333333  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "clinical    0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "firstorder  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "glcm        0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "gldm        0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "glrlm       0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "glszm       0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "ngtdm       0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "shape       0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "             11   12   13        14   15   16   17  \n",
       "PETparam    0.0  0.0  0.0  0.333333  0.0  0.0  0.0  \n",
       "clinical    0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "firstorder  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "glcm        0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "gldm        0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "glrlm       0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "glszm       0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "ngtdm       0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "shape       0.0  0.0  0.0  0.000000  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PET</th>\n",
       "      <td>PETparam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PET</th>\n",
       "      <td>clinical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PET</th>\n",
       "      <td>firstorder</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PET</th>\n",
       "      <td>glcm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PET</th>\n",
       "      <td>gldm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index    0    1         2         3    4    5    6    7    8    9  \\\n",
       "PET    PETparam  0.0  0.0  0.333333  0.333333  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "PET    clinical  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "PET  firstorder  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "PET        glcm  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "PET        gldm  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      10   11   12   13        14   15   16   17  \n",
       "PET  0.0  0.0  0.0  0.0  0.333333  0.0  0.0  0.0  \n",
       "PET  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "PET  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "PET  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "PET  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_df = pet_df.reset_index()\n",
    "pet_df.index = ['PET'] * pet_df.shape[0]\n",
    "\n",
    "ct_df = ct_df.reset_index()\n",
    "ct_df.index = ['CT'] * ct_df.shape[0]\n",
    "\n",
    "df = pd.concat((pet_df, ct_df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-276-d7c54853fb46>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-276-d7c54853fb46>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    for cluster_num cluster_nums:\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bic_pfs_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-6cb0d60f911b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msorted_cluster_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbic_row_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbic_row_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcomb_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbic_pfs_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbic_not_pfs_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m results_id =  np.concatenate((\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m'Progression-free Survival'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbic_pfs_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bic_pfs_stats' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_cluster_idx = np.concatenate((bic_row_ids, bic_row_ids))\n",
    "comb_results = np.concatenate((bic_pfs_stats, bic_not_pfs_stats))\n",
    "\n",
    "results_id =  np.concatenate((\n",
    "    ['Progression-free Survival'] * len(bic_pfs_stats), \n",
    "    ['Other Event'] * len(bic_not_pfs_stats)\n",
    "))\n",
    "df_bic_stats = pd.DataFrame(\n",
    "    {\n",
    "        'comb_results': comb_results,\n",
    "        'results_id': results_id\n",
    "    },\n",
    "    index=sorted_cluster_idx,\n",
    ")\n",
    "df_bic_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_cluster_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-c08bff28e6f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m sns.barplot(\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted_cluster_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'comb_results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'results_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_cluster_idx' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# * Hue row (patient) clusters according to outcome. Capable of producing clusters with\n",
    "#   pure outcomes? If so, which features separates a pure PFS outcome cluster from a \n",
    "#   cluster with no PFS outcomes?\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(\n",
    "    x=sorted_cluster_idx,\n",
    "    y='comb_results',\n",
    "    hue='results_id',\n",
    "    data=df_bic_stats,\n",
    "    palette='muted',\n",
    ")\n",
    "plt.legend(\n",
    "    loc='upper center', \n",
    "    fontsize=16,\n",
    "    bbox_to_anchor=(0.5, 1.1),\n",
    "    ncol=3, \n",
    "    fancybox=True, \n",
    "    shadow=True\n",
    ")\n",
    "plt.xlabel('Cluster Indicator', fontsize=16)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Possible to separate patients based on clinical outcomes whilst\n",
    "#   identifying separating features?\n",
    "fig, (cbar_ax, map_ax) = plt.subplots(\n",
    "    nrows=2, figsize=(10, 10),  \n",
    "    gridspec_kw={'height_ratios':[0.025, 1]}\n",
    ")\n",
    "sns.heatmap(\n",
    "    fit_data, ax=map_ax, robust=True, \n",
    "    cmap=plt.cm.RdBu_r, fmt='f', \n",
    "    vmin=np.min(fit_data), \n",
    "    vmax=np.max(fit_data),\n",
    "    cbar=False\n",
    ")\n",
    "#coords = checker_coords(bic_model, best_config['n_clusters'])\n",
    "#for num in coords.index:\n",
    "#    plt.plot(\n",
    "#        (coords.loc[num, ['x1', 'x2', 'x2', 'x1', 'x1']]),\n",
    "#        (coords.loc[num, ['y1', 'y1', 'y2', 'y2', 'y1']]),\n",
    "#        linewidth=2, c='orangered' #darkred\n",
    "#)\n",
    "fig.colorbar(\n",
    "    map_ax.get_children()[0], \n",
    "    cax=cbar_ax, \n",
    "    orientation='horizontal'\n",
    ")\n",
    "map_ax.set_xlabel('Features', fontsize=18)\n",
    "map_ax.set_ylabel('Patients', fontsize=18)\n",
    "map_ax.set_xticklabels('')\n",
    "map_ax.set_yticklabels('')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Coclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)   \n",
    "co_grid = ParameterGrid(\n",
    "    {\n",
    "        'n_clusters': [\n",
    "            np.random.choice(np.arange(30), size=1)[0] for _ in range(25)\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "# Id config with best score results and plot with grid.\n",
    "co_scores = {}\n",
    "for num, co_param_config in enumerate(co_grid):\n",
    "    try:\n",
    "        co_model = SpectralCoclustering(\n",
    "            random_state=SEED, svd_method='arpack'\n",
    "        )\n",
    "        co_clusters = biclusters(\n",
    "            co_model, X_std, co_param_config\n",
    "        )\n",
    "        co_scores[num] = co_clusters.external_metrics\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best coclustering config.\n",
    "avg_co_scores = []\n",
    "for scores in co_scores.values():\n",
    "    _, non_inf_idx = np.where(scores.values != float('inf'))\n",
    "    score = sum(scores.values.ravel()[non_inf_idx]) / len(non_inf_idx)\n",
    "    avg_co_scores.append(score)\n",
    "    \n",
    "best_config = co_grid[np.argmin(avg_co_scores)]\n",
    "best_config, min(avg_bic_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_model = SpectralCoclustering(\n",
    "    random_state=SEED, svd_method='arpack'\n",
    ")\n",
    "co_model.set_params(**best_config)\n",
    "co_model.fit(X_std)\n",
    "row_sorted = X_std[np.argsort(co_model.row_labels_), :]\n",
    "fit_data = row_sorted[:, np.argsort(co_model.column_labels_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Hue row (patient) clusters according to outcome. Capable of producing clusters with\n",
    "#   pure outcomes? If so, which features separates a pure PFS outcome cluster from a \n",
    "#   cluster with no PFS outcomes?\n",
    "\n",
    "# The proportion of outcomes per cocluster.\n",
    "co_pfs_stats, co_not_pfs_stats, cluster_ids = [], [], []\n",
    "for cluster_idx in np.unique(co_model.row_labels_):\n",
    "    cluster_ids.append(cluster_idx)\n",
    "    targets = np.where(co_model.row_labels_ == cluster_idx)\n",
    "    co_pfs_stats.append(sum(y[targets] == 0) / np.size(y))\n",
    "    co_not_pfs_stats.append(sum(y[targets] == 1) / np.size(y))\n",
    "sum(co_pfs_stats), sum(co_not_pfs_stats), len(cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(co_pfs_stats), len(co_not_pfs_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cluster_idx = np.concatenate((cluster_ids, cluster_ids))\n",
    "comb_results = np.concatenate((co_pfs_stats, co_not_pfs_stats))\n",
    "\n",
    "results_id =  np.concatenate((\n",
    "    ['Progression-free Survival'] * len(co_pfs_stats), \n",
    "    ['Other Event'] * len(co_not_pfs_stats)\n",
    "))\n",
    "df_co_stats = pd.DataFrame(\n",
    "    {\n",
    "        'comb_results': comb_results,\n",
    "        'results_id': results_id\n",
    "    },\n",
    "    index=sorted_cluster_idx,\n",
    ")\n",
    "df_co_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Hue row (patient) clusters according to outcome. Capable of producing clusters with\n",
    "#   pure outcomes? If so, which features separates a pure PFS outcome cluster from a \n",
    "#   cluster with no PFS outcomes?\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(\n",
    "    x=sorted_cluster_idx,\n",
    "    y='comb_results',\n",
    "    hue='results_id',\n",
    "    data=df_co_stats,\n",
    "    palette='muted',\n",
    ")\n",
    "plt.legend(\n",
    "    loc='upper center', \n",
    "    fontsize=16,\n",
    "    bbox_to_anchor=(0.5, 1.1),\n",
    "    ncol=3, \n",
    "    fancybox=True, \n",
    "    shadow=True\n",
    ")\n",
    "plt.xlabel('Cluster Indicator', fontsize=16)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (cbar_ax, map_ax) = plt.subplots(\n",
    "    nrows=2, figsize=(10, 10),  \n",
    "    gridspec_kw={'height_ratios':[0.025, 1]}\n",
    ")\n",
    "sns.heatmap(\n",
    "    fit_data, ax=map_ax, robust=True, \n",
    "    cmap=plt.cm.RdBu_r, fmt='f', \n",
    "    vmin=np.min(fit_data), \n",
    "    vmax=np.max(fit_data),\n",
    "    cbar=False\n",
    ")\n",
    "#coords = checker_coords(bic_model, best_config['n_clusters'])\n",
    "#for num in coords.index:\n",
    "#    plt.plot(\n",
    "#        (coords.loc[num, ['x1', 'x2', 'x2', 'x1', 'x1']]),\n",
    "#        (coords.loc[num, ['y1', 'y1', 'y2', 'y2', 'y1']]),\n",
    "#        linewidth=2, c='orangered' #darkred\n",
    "#)\n",
    "fig.colorbar(\n",
    "    map_ax.get_children()[0], \n",
    "    cax=cbar_ax, \n",
    "    orientation='horizontal'\n",
    ")\n",
    "map_ax.set_xlabel('Features', fontsize=18)\n",
    "map_ax.set_ylabel('Patients', fontsize=18)\n",
    "map_ax.set_xticklabels('')\n",
    "map_ax.set_yticklabels('')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DGUFS & Group LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgufs import DGUFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "dgufs_param_grid = ParameterGrid(\n",
    "    {\n",
    "        'num_clusters': [\n",
    "            np.random.choice(np.arange(30), size=1)[0] for _ in range(25)\n",
    "        ],\n",
    "        'num_features': [\n",
    "            np.random.choice(np.arange(500), size=1)[0] for _ in range(25)\n",
    "        ],\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dgufs_param_config in dgufs_param_grid:\n",
    "    model = DGUFS(**dgufs_param_config)\n",
    "    model.fit(X_std)\n",
    "    # Measure quality of clusters and ID best config.\n",
    "    # Apply group LASSO to clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
